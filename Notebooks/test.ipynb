{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_azure_openai_client():\n",
    "    load_dotenv()  # Load environment variables from .env.\n",
    "\n",
    "    endpoint = os.getenv(\"ENDPOINT_URL\", \"https://your-azure-openai-endpoint.openai.azure.com/\")\n",
    "    deployment = os.getenv(\"DEPLOYMENT_NAME\", \"your-deployment-name\")\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        api_version=\"2024-05-01-preview\",\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    return client, deployment\n",
    "\n",
    "def calculatePerplexity_gpt3(prompt, client, deployment):\n",
    "    prompt = prompt.replace('\\x00','')\n",
    "    responses = None\n",
    "    while responses is None:\n",
    "        try:\n",
    "            responses = client.chat.completions.create(\n",
    "                model=deployment,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": prompt\n",
    "                            }\n",
    "                        ]\n",
    "                    },\n",
    "                ],\n",
    "                max_tokens=0,\n",
    "                logprobs=True,\n",
    "                top_logprobs=5,\n",
    "                temperature=1.0,\n",
    "                top_p=0.95,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0,\n",
    "                stop=None,\n",
    "                stream=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"API request failed: {e}\")\n",
    "            responses = None\n",
    "    data = responses.choices[0].logprobs\n",
    "    all_prob = [token_logprob.logprob for token_logprob in data.content if token_logprob.logprob is not None]\n",
    "    p1 = np.exp(-np.mean(all_prob))\n",
    "    return p1, all_prob, np.mean(all_prob)\n",
    "\n",
    "def read_and_chunk_file(file_path, chunk_size=1000):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    # Split text into chunks of specified size\n",
    "    chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "def process_file(file_path, client, deployment):\n",
    "    chunks = read_and_chunk_file(file_path)\n",
    "    scores = []\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        p1, all_prob, mean_logprob = calculatePerplexity_gpt3(chunk, client, deployment)\n",
    "        scores.append({'chunk': idx, 'perplexity': p1, 'mean_logprob': mean_logprob})\n",
    "        print(f\"File: {file_path}, Chunk {idx}: Perplexity={p1}, Mean Log Probability={mean_logprob}\")\n",
    "    return scores\n",
    "\n",
    "def main():\n",
    "    if len(sys.argv) < 2:\n",
    "        print(\"Usage: python run2.py <path_to_text_file1> [<path_to_text_file2> ...]\")\n",
    "        sys.exit(1)\n",
    "    client, deployment = load_azure_openai_client()\n",
    "    all_scores = {}\n",
    "    for file_path in sys.argv[1:]:\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "        scores = process_file(file_path, client, deployment)\n",
    "        all_scores[file_path] = scores\n",
    "    # Optionally, save all scores to a JSON file\n",
    "    \n",
    "    with open('all_scores.json', 'w') as outfile:\n",
    "        json.dump(all_scores, outfile, indent=4)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaiold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
