{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-BT6C5Ye84XRcAIziQcomqH9L2PnJv', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='the', bytes=[116, 104, 101], logprob=-0.037899404764175415, top_logprobs=[TopLogprob(token='the', bytes=[116, 104, 101], logprob=-0.037899404764175415), TopLogprob(token='Quick', bytes=[81, 117, 105, 99, 107], logprob=-4.025730609893799), TopLogprob(token='quick', bytes=[113, 117, 105, 99, 107], logprob=-4.641941547393799), TopLogprob(token='The', bytes=[84, 104, 101], logprob=-5.227684497833252), TopLogprob(token='\"', bytes=[34], logprob=-6.394516468048096)]), ChatCompletionTokenLogprob(token=' lazy', bytes=[32, 108, 97, 122, 121], logprob=-0.00036846695002168417, top_logprobs=[TopLogprob(token=' lazy', bytes=[32, 108, 97, 122, 121], logprob=-0.00036846695002168417), TopLogprob(token=' **', bytes=[32, 42, 42], logprob=-7.906416416168213), TopLogprob(token=' Lazy', bytes=[32, 76, 97, 122, 121], logprob=-17.006155014038086), TopLogprob(token=' \"', bytes=[32, 34], logprob=-17.434640884399414), TopLogprob(token=' *', bytes=[32, 42], logprob=-17.540067672729492)]), ChatCompletionTokenLogprob(token=' dog', bytes=[32, 100, 111, 103], logprob=0.0, top_logprobs=[TopLogprob(token=' dog', bytes=[32, 100, 111, 103], logprob=0.0), TopLogprob(token=\" dog's\", bytes=[32, 100, 111, 103, 39, 115], logprob=-18.578060150146484), TopLogprob(token=' dogs', bytes=[32, 100, 111, 103, 115], logprob=-18.99859619140625), TopLogprob(token=' **', bytes=[32, 42, 42], logprob=-20.713253021240234), TopLogprob(token=' fox', bytes=[32, 102, 111, 120], logprob=-21.12340545654297)]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.6850025057792664, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-0.6850025057792664), TopLogprob(token='<|end|>', bytes=None, logprob=-0.7013599276542664), TopLogprob(token='<|end|>', bytes=None, logprob=-14.614930152893066), TopLogprob(token='<|end|>', bytes=None, logprob=-15.598921775817871), TopLogprob(token='!', bytes=[33], logprob=-18.014863967895508)])], refusal=None), message=ChatCompletionMessage(content='the lazy dog.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'low'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1746275021, model='gpt-4.5-preview-2025-02-27', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=5, prompt_tokens=14, total_tokens=19, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n",
      "Logits: ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='the', bytes=[116, 104, 101], logprob=-0.037899404764175415, top_logprobs=[TopLogprob(token='the', bytes=[116, 104, 101], logprob=-0.037899404764175415), TopLogprob(token='Quick', bytes=[81, 117, 105, 99, 107], logprob=-4.025730609893799), TopLogprob(token='quick', bytes=[113, 117, 105, 99, 107], logprob=-4.641941547393799), TopLogprob(token='The', bytes=[84, 104, 101], logprob=-5.227684497833252), TopLogprob(token='\"', bytes=[34], logprob=-6.394516468048096)]), ChatCompletionTokenLogprob(token=' lazy', bytes=[32, 108, 97, 122, 121], logprob=-0.00036846695002168417, top_logprobs=[TopLogprob(token=' lazy', bytes=[32, 108, 97, 122, 121], logprob=-0.00036846695002168417), TopLogprob(token=' **', bytes=[32, 42, 42], logprob=-7.906416416168213), TopLogprob(token=' Lazy', bytes=[32, 76, 97, 122, 121], logprob=-17.006155014038086), TopLogprob(token=' \"', bytes=[32, 34], logprob=-17.434640884399414), TopLogprob(token=' *', bytes=[32, 42], logprob=-17.540067672729492)]), ChatCompletionTokenLogprob(token=' dog', bytes=[32, 100, 111, 103], logprob=0.0, top_logprobs=[TopLogprob(token=' dog', bytes=[32, 100, 111, 103], logprob=0.0), TopLogprob(token=\" dog's\", bytes=[32, 100, 111, 103, 39, 115], logprob=-18.578060150146484), TopLogprob(token=' dogs', bytes=[32, 100, 111, 103, 115], logprob=-18.99859619140625), TopLogprob(token=' **', bytes=[32, 42, 42], logprob=-20.713253021240234), TopLogprob(token=' fox', bytes=[32, 102, 111, 120], logprob=-21.12340545654297)]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.6850025057792664, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-0.6850025057792664), TopLogprob(token='<|end|>', bytes=None, logprob=-0.7013599276542664), TopLogprob(token='<|end|>', bytes=None, logprob=-14.614930152893066), TopLogprob(token='<|end|>', bytes=None, logprob=-15.598921775817871), TopLogprob(token='!', bytes=[33], logprob=-18.014863967895508)])], refusal=None)\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "import os  \n",
    "import base64\n",
    "from openai import AzureOpenAI  \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "endpoint = os.getenv(\"ENDPOINT_URL\", \"https://aicoe-open-ai-np-002.openai.azure.com/\")  \n",
    "deployment = os.getenv(\"AZURE_OPENAI_GPT_4_MODEL\")  \n",
    "  \n",
    "\n",
    "  \n",
    "client = AzureOpenAI(  \n",
    "    azure_endpoint=endpoint,  \n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    ")  \n",
    "  \n",
    "chat_prompt = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"quick bron fox jumps over ___ \"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "\n",
    "] \n",
    "    \n",
    "messages = chat_prompt \n",
    "\n",
    "completion = client.chat.completions.create(  \n",
    "    model=deployment,  \n",
    "    messages=messages,\n",
    "    max_tokens=800,\n",
    "    logprobs=True,\n",
    "    top_logprobs=5,  \n",
    "    temperature=0.7,  \n",
    "    top_p=0.95,  \n",
    "    frequency_penalty=0,  \n",
    "    presence_penalty=0,\n",
    "    stop=None,  \n",
    "    stream=False\n",
    ")  \n",
    "  \n",
    "print(completion)  \n",
    "\n",
    "for choice in completion.choices:  \n",
    "    print(\"Logits:\", choice.logprobs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## membership inference attack 1- min k probability\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionTokenLogprob(token='the', bytes=[116, 104, 101], logprob=-0.037899404764175415, top_logprobs=[TopLogprob(token='the', bytes=[116, 104, 101], logprob=-0.037899404764175415), TopLogprob(token='Quick', bytes=[81, 117, 105, 99, 107], logprob=-4.025730609893799), TopLogprob(token='quick', bytes=[113, 117, 105, 99, 107], logprob=-4.641941547393799), TopLogprob(token='The', bytes=[84, 104, 101], logprob=-5.227684497833252), TopLogprob(token='\"', bytes=[34], logprob=-6.394516468048096)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choice.logprobs.content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
